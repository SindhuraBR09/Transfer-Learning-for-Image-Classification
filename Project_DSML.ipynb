{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c313c6",
   "metadata": {},
   "source": [
    "<b>Name</b> : Sindhura Bagodu Ramachandra\n",
    "\n",
    "<b>USC ID</b> : 4628596426\n",
    "\n",
    "<b>Github username</b> : SindhuraBagodu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4878fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# import tensorflow as tf\n",
    "# from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc82c2",
   "metadata": {},
   "source": [
    "##### 1. Transfer Learning for Image Classification1\n",
    "\n",
    "It is highly recommended that you complete this project using Keras2 and Python.\n",
    "\n",
    "(a) In this problem, we are trying to build a classifier that distinguishes images of 20 bird species. You are provided with text data in twenty folders.\n",
    "\n",
    "###### (b) Data Exploration and Pre-processing\n",
    "\n",
    "i. Images in each class are given in separate folders. The file Classes.xlsx provides the classes assigned to the bird species images in each folder. Therefore, you encode your classes using one-hot encoding and Classes.xlsx.\n",
    "\n",
    "ii. Randomly select d0.7ni images from each folder as your training set, [0.15ni] as validation set, and the rest as your test set, where ni is the number of images in folder i and dxe is the ceiling of x. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a7db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs('./output')\n",
    "    os.makedirs('./output/train')\n",
    "    os.makedirs('./output/test')\n",
    "\n",
    "    os.listdir('./output')\n",
    "    \n",
    "except OSError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11956249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "38\n",
      "42\n",
      "51\n",
      "41\n",
      "50\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "41\n",
      "50\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n",
      "42\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "root_dir = '../Data/images'\n",
    "classes = ['005.Crested_Auklet', '013.Bobolink', '015.Lazuli_Bunting', '023.Brandt_Cormorant', '040.Olive_sided_Flycatcher', '041.Scissor_tailed_Flycatcher', '067.Anna_Hummingbird', '072.Pomarine_Jaeger', '076.Dark_eyed_Junco', '081.Pied_Kingfisher', '082.Ringed_Kingfisher', '086.Pacific_Loon', '099.Ovenbird', '104.American_Pipit', '127.Savannah_Sparrow', '135.Bank_Swallow', '141.Artic_Tern', '149.Brown_Thrasher', '156.White_eyed_Vireo', '168.Kentucky_Warbler']\n",
    "\n",
    "for clss in classes:\n",
    "#     print('------------' + clss + '-------------')\n",
    "    dirtry = root_dir + '/' + clss\n",
    "    files = os.listdir(dirtry)\n",
    "    np.random.shuffle(files)\n",
    "    \n",
    "    base_outdir = './output/'\n",
    "\n",
    "    for folder in ['train', 'test', 'validation']:\n",
    "        target_dir = base_outdir + folder\n",
    "        os.makedirs(target_dir + '/' + clss)\n",
    "        target_class = target_dir + '/' + clss\n",
    "\n",
    "        if folder == 'train':\n",
    "            print(math.ceil(0.7*len(files)))\n",
    "            images_to_pass = files[: math.ceil(0.7*len(files))]\n",
    "            for img in images_to_pass:\n",
    "                img = dirtry + '/' + img\n",
    "                shutil.copy(img, target_class)\n",
    "                \n",
    "        elif folder == 'validation':\n",
    "            print(math.ceil(0.85*len(files)))\n",
    "            images_to_pass = files[math.ceil(0.7*len(files)): math.ceil(0.85*len(files))]\n",
    "            for img in images_to_pass:\n",
    "                img = dirtry + '/' + img\n",
    "                try:\n",
    "                    shutil.copy(img, target_class)\n",
    "                except OSError as e:\n",
    "                      print(e)\n",
    "        else:\n",
    "            images_to_pass = files[math.ceil(0.85*len(files)):]\n",
    "            for img in images_to_pass:\n",
    "                img = dirtry + '/' + img\n",
    "                shutil.copy(img, target_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5842f52b",
   "metadata": {},
   "source": [
    "\n",
    "iii. In order for all the images to have the same size, zero-pad or resize the images in your dataset. This can be done using various tools, including OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63db325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(path):\n",
    "    \n",
    "    for clss in classes:\n",
    "        dirtry = path + '/' + clss\n",
    "        files = os.listdir(dirtry)\n",
    "        for item in files:\n",
    "            f_img = dirtry+\"/\"+item\n",
    "            img = Image.open(f_img)\n",
    "            img = img.resize((224,224))\n",
    "            img.save(f_img)            \n",
    "\n",
    "resize('./output/train/')\n",
    "resize('./output/validation/')\n",
    "resize('./output/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55903bb2",
   "metadata": {},
   "source": [
    "##### (c) Transfer Learning\n",
    "\n",
    "i. When dealing with classification of relatively small image datasets, deep networks may not perform very well because of not having enough data to train them. In such cases, one usually uses transfer learning, which uses deep learning models that are trained on very large datasets such as ImageNet as feature extractors. The idea is that such deep networks have learned to extract meaningful features from an image using their layers, and those features can be used in learning other tasks. In order to do that, usually the last layer or the last few layers of the pre-trained network are removed, and the response of the layer before the removed layers to the images in the new dataset is used as a feature vector to train one more multiple replacement layers. The dataset in this task has only around 50-60 images per class. Given that we have 20 classes, training a deep network with such a small dataset may not yield desirable results. In this project, you will use pre-trained models EfficientNetB0 and VGG16. For both pre-trained networks, you will only train the last fully connected layer, and will freeze all layers before them (i.e. we do not change their parameters during training) and use the outputs of the penultimate layer in the original pre-trained model as the features extracted from each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04444404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bird_class</th>\n",
       "      <th>Birds_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005.Crested_Auklet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>013.Bobolink</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>015.Lazuli_Bunting</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>023.Brandt_Cormorant</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>040.Olive_sided_Flycatcher</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>041.Scissor_tailed_Flycatcher</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>067.Anna_Hummingbird</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>072.Pomarine_Jaeger</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>076.Dark_eyed_Junco</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>081.Pied_Kingfisher</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>082.Ringed_Kingfisher</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>086.Pacific_Loon</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>099.Ovenbird</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>104.American_Pipit</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>127.Savannah_Sparrow</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>135.Bank_Swallow</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>141.Artic_Tern</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>149.Brown_Thrasher</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>156.White_eyed_Vireo</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>168.Kentucky_Warbler</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Bird_class  Birds_encoded\n",
       "0              005.Crested_Auklet              0\n",
       "1                    013.Bobolink              1\n",
       "2              015.Lazuli_Bunting              2\n",
       "3            023.Brandt_Cormorant              3\n",
       "4      040.Olive_sided_Flycatcher              4\n",
       "5   041.Scissor_tailed_Flycatcher              5\n",
       "6            067.Anna_Hummingbird              6\n",
       "7             072.Pomarine_Jaeger              7\n",
       "8             076.Dark_eyed_Junco              8\n",
       "9             081.Pied_Kingfisher              9\n",
       "10          082.Ringed_Kingfisher             10\n",
       "11               086.Pacific_Loon             11\n",
       "12                   099.Ovenbird             12\n",
       "13             104.American_Pipit             13\n",
       "14           127.Savannah_Sparrow             14\n",
       "15               135.Bank_Swallow             15\n",
       "16                 141.Artic_Tern             16\n",
       "17             149.Brown_Thrasher             17\n",
       "18           156.White_eyed_Vireo             18\n",
       "19           168.Kentucky_Warbler             19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "bird_df = pd.DataFrame(classes, columns=['Bird_class'])\n",
    "bird_df['Birds_encoded'] = labelencoder.fit_transform(bird_df['Bird_class'])\n",
    "bird_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64226a61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20492/3918066349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatagen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# train_it = datagen.flow_from_directory('./output/train/', class_mode='categorical', batch_size=64)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# test_it = datagen.flow_from_directory('./output/train/', class_mode='binary', batch_size=64)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "classes_label = ['005.Crested_Auklet', '013.Bobolink', '015.Lazuli_Bunting', '023.Brandt_Cormorant', '040.Olive_sided_Flycatcher', '041.Scissor_tailed_Flycatcher', '067.Anna_Hummingbird', '072.Pomarine_Jaeger', '076.Dark_eyed_Junco', '081.Pied_Kingfisher', '082.Ringed_Kingfisher', '086.Pacific_Loon', '099.Ovenbird', '104.American_Pipit', '127.Savannah_Sparrow', '135.Bank_Swallow', '141.Artic_Tern', '149.Brown_Thrasher', '156.White_eyed_Vireo', '168.Kentucky_Warbler']\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=20,\tzoom_range=0.15, rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/output/train', target_size=(224,224), batch_size=5,classes=classes_label, class_mode='categorical', shuffle=True)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/output/validation',target_size=(224,224),batch_size=5,classes=classes_label,class_mode='categorical',shuffle=False)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory('/content/drive/My Drive/Colab Notebooks/output/test',target_size=(224,224),batch_size=5,classes=classes_label,class_mode='categorical',shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d8fb19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.12.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.5.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\SINDHURA\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7102e09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.12.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp310-cp310-win_amd64.whl (266.3 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.43.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.28.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.6)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sindhura\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.0)\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, wrapt, typing-extensions, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.5.1\n",
      "    Uninstalling google-auth-oauthlib-0.5.1:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.5.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.12.2\n",
      "    Uninstalling tensorboard-1.12.2:\n",
      "      Successfully uninstalled tensorboard-1.12.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.7.0\n",
      "    Uninstalling keras-2.7.0:\n",
      "      Successfully uninstalled keras-2.7.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.12.0\n",
      "    Uninstalling tensorflow-1.12.0:\n",
      "      Successfully uninstalled tensorflow-1.12.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-22.12.6 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.11.0 libclang-14.0.6 opt-einsum-3.3.0 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 typing-extensions-4.4.0 wrapt-1.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\SINDHURA\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2236b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d03608",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30352/3242307772.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVERSION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaac02f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0bd47640a75636bf2879de1475f0d4849ef351f39e5c313145e8f8e67e87269"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
